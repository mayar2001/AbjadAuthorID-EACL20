{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14560560,"sourceType":"datasetVersion","datasetId":9300282}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_excel(\"/kaggle/input/authorshipclassficiationval/AuthorshipClassficiationVal.xlsx\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:08:33.376964Z","iopub.execute_input":"2026-01-20T16:08:33.377713Z","iopub.status.idle":"2026-01-20T16:08:33.919743Z","shell.execute_reply.started":"2026-01-20T16:08:33.377678Z","shell.execute_reply":"2026-01-20T16:08:33.918881Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:08:33.921317Z","iopub.execute_input":"2026-01-20T16:08:33.921777Z","iopub.status.idle":"2026-01-20T16:08:33.931230Z","shell.execute_reply.started":"2026-01-20T16:08:33.921734Z","shell.execute_reply":"2026-01-20T16:08:33.930387Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"     id                               text_in_author_style      author\n0  3835  من طفل في الخمسين\\n\\nعمري ما احتفلت أو حفلت بع...  يوسف إدريس\n1  3836  ذلك الزمن العام هو العداد العام الذي\\n\\nدام يع...  يوسف إدريس\n2  3837  مصر الغنية المثقفة المصنِّعة، والعرب\\n\\nوقد\\n\\...  يوسف إدريس\n3  3838  ولأنها غريبة وراودتني فيها عن الناس وعن الحياة...  يوسف إدريس\n4  3839  وليس ما ذكرته مرارة ولا ندمًا؛ فقد كان لا يمكن...  يوسف إدريس","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>text_in_author_style</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3835</td>\n      <td>من طفل في الخمسين\\n\\nعمري ما احتفلت أو حفلت بع...</td>\n      <td>يوسف إدريس</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3836</td>\n      <td>ذلك الزمن العام هو العداد العام الذي\\n\\nدام يع...</td>\n      <td>يوسف إدريس</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3837</td>\n      <td>مصر الغنية المثقفة المصنِّعة، والعرب\\n\\nوقد\\n\\...</td>\n      <td>يوسف إدريس</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3838</td>\n      <td>ولأنها غريبة وراودتني فيها عن الناس وعن الحياة...</td>\n      <td>يوسف إدريس</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3839</td>\n      <td>وليس ما ذكرته مرارة ولا ندمًا؛ فقد كان لا يمكن...</td>\n      <td>يوسف إدريس</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:08:33.932219Z","iopub.execute_input":"2026-01-20T16:08:33.932502Z","iopub.status.idle":"2026-01-20T16:08:33.949293Z","shell.execute_reply.started":"2026-01-20T16:08:33.932476Z","shell.execute_reply":"2026-01-20T16:08:33.948381Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"4157"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print(df[\"author\"].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:08:35.833565Z","iopub.execute_input":"2026-01-20T16:08:35.834134Z","iopub.status.idle":"2026-01-20T16:08:35.839797Z","shell.execute_reply.started":"2026-01-20T16:08:35.834103Z","shell.execute_reply":"2026-01-20T16:08:35.838881Z"}},"outputs":[{"name":"stdout","text":"['يوسف إدريس' 'فؤاد زكريا' 'حسن حنفي' 'عبد الغفار مكاوي' 'كامل كيلاني'\n 'نوال السعداوي' 'أحمد شوقي' 'أحمد تيمور باشا' 'ثروت أباظة' 'سلامة موسى'\n 'جبران خليل جبران' 'روبرت بار' 'ويليام شيكسبير' 'طه حسين' 'أمين الريحاني'\n 'غوستاف لوبون' 'نجيب محفوظ' 'أحمد أمين' 'محمد حسين هيكل' 'جُرجي زيدان'\n 'عباس محمود العقاد']\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:08:36.175785Z","iopub.execute_input":"2026-01-20T16:08:36.176111Z","iopub.status.idle":"2026-01-20T16:08:36.184359Z","shell.execute_reply.started":"2026-01-20T16:08:36.176086Z","shell.execute_reply":"2026-01-20T16:08:36.183470Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"id                      0\ntext_in_author_style    0\nauthor                  0\ndtype: int64"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom openai import OpenAI\nimport time\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom threading import Lock\nimport json\nfrom sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\nimport warnings\nwarnings.filterwarnings('ignore')\n\nAPI_KEYS = [\n## api key\n]\n\napi_index = 0\napi_lock = Lock()\nrequest_times = []\nrequest_lock = Lock()\n\nRPM_LIMIT = 40\nRATE_WINDOW = 60  \n\ndef get_next_api_key():\n    \"\"\"Rotate through API keys\"\"\"\n    global api_index\n    with api_lock:\n        key = API_KEYS[api_index]\n        api_index = (api_index + 1) % len(API_KEYS)\n        return key\n\ndef rate_limit_check():\n    \"\"\"Ensure we don't exceed RPM limit\"\"\"\n    with request_lock:\n        current_time = time.time()\n        request_times[:] = [t for t in request_times if current_time - t < RATE_WINDOW]\n        \n        if len(request_times) >= RPM_LIMIT:\n            # Calculate sleep time\n            oldest_request = request_times[0]\n            sleep_time = RATE_WINDOW - (current_time - oldest_request)\n            if sleep_time > 0:\n                print(f\"Rate limit reached. Sleeping for {sleep_time:.2f} seconds...\")\n                time.sleep(sleep_time)\n        \n        request_times.append(time.time())\n\ndef create_classification_prompt(text, authors_list):\n    \"\"\"\n    Create a well-engineered prompt for authorship classification\n    \"\"\"\n    prompt = f\"\"\"أنت خبير في تحليل الأسلوب الأدبي العربي. مهمتك هي تحديد كاتب النص التالي من بين قائمة من المؤلفين.\n\nقائمة المؤلفين المحتملين:\n{', '.join(authors_list)}\n\nالنص المراد تحليله:\n\\\"\\\"\\\"{text}\\\"\\\"\\\"\n\nقم بتحليل:\n1. الأسلوب الأدبي والبلاغي\n2. المفردات والتراكيب اللغوية المستخدمة\n3. الموضوعات والأفكار المطروحة\n4. السمات الأسلوبية المميزة\n\nبناءً على تحليلك، أجب فقط باسم المؤلف من القائمة المعطاة. لا تضف أي تفسيرات أو نصوص إضافية.\n\nالإجابة (اسم المؤلف فقط):\"\"\"\n    \n    return prompt\n\ndef classify_text(row_data, authors_list, max_retries=3):\n    \"\"\"\n    Classify a single text using the LLM with retry logic\n    \"\"\"\n    text_id = row_data['id']\n    text = row_data['text_in_author_style']\n    true_author = row_data['author']\n    \n    for attempt in range(max_retries):\n        try:\n            # Rate limiting\n            rate_limit_check()\n            \n            # Get API key\n            api_key = get_next_api_key()\n            \n            # Create client\n            client = OpenAI(\n                base_url=\"https://integrate.api.nvidia.com/v1\",\n                api_key=api_key\n            )\n            \n            # Create prompt\n            prompt = create_classification_prompt(text, authors_list)\n            \n            # Make API call\n            completion = client.chat.completions.create(\n                model=\"deepseek-ai/deepseek-v3.2\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=0.3,  # Lower temperature for more consistent classification\n                top_p=0.95,\n                max_tokens=100,  # We only need the author name\n                extra_body={\"chat_template_kwargs\": {\"thinking\": True}},\n                stream=True\n            )\n            \n            # Collect response\n            predicted_author = \"\"\n            for chunk in completion:\n                if not getattr(chunk, \"choices\", None):\n                    continue\n                if chunk.choices and chunk.choices[0].delta.content is not None:\n                    predicted_author += chunk.choices[0].delta.content\n            \n            # Clean the response\n            predicted_author = predicted_author.strip()\n            \n            # Validate that the predicted author is in the list\n            if predicted_author not in authors_list:\n                # Try to find closest match\n                for author in authors_list:\n                    if author in predicted_author or predicted_author in author:\n                        predicted_author = author\n                        break\n            \n            print(f\"✓ ID {text_id}: True={true_author}, Predicted={predicted_author}\")\n            \n            return {\n                'id': text_id,\n                'text': text,\n                'true_author': true_author,\n                'predicted_author': predicted_author,\n                'success': True\n            }\n            \n        except Exception as e:\n            print(f\"✗ ID {text_id} - Attempt {attempt + 1} failed: {str(e)}\")\n            if attempt < max_retries - 1:\n                time.sleep(2)  # Wait before retry\n            else:\n                print(f\"✗ ID {text_id} - All attempts failed. Skipping.\")\n                return None\n    \n    return None\n\ndef parallel_classify(df, max_workers=5):\n    \"\"\"\n    Classify texts in parallel using ThreadPoolExecutor\n    \"\"\"\n    # Get unique authors\n    authors_list = df['author'].unique().tolist()\n    \n    # Prepare data for parallel processing\n    rows_data = []\n    for idx, row in df.iterrows():\n        rows_data.append({\n            'id': row['id'],\n            'text_in_author_style': row['text_in_author_style'],\n            'author': row['author']\n        })\n    \n    results = []\n    \n    # Process in parallel\n    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n        # Submit all tasks\n        future_to_row = {\n            executor.submit(classify_text, row_data, authors_list): row_data \n            for row_data in rows_data\n        }\n        \n        # Collect results as they complete\n        for future in as_completed(future_to_row):\n            result = future.result()\n            if result is not None and result['success']:\n                results.append(result)\n    \n    return pd.DataFrame(results)\n\ndef evaluate_predictions(results_df):\n    \"\"\"\n    Calculate evaluation metrics\n    \"\"\"\n    y_true = results_df['true_author'].values\n    y_pred = results_df['predicted_author'].values\n    \n    # Accuracy\n    accuracy = accuracy_score(y_true, y_pred)\n    \n    # F1 Score (weighted average for multi-class)\n    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"EVALUATION METRICS\")\n    print(\"=\"*60)\n    print(f\"Total Samples Processed: {len(results_df)}\")\n    print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    print(f\"F1 Score (Weighted): {f1_weighted:.4f}\")\n    print(f\"F1 Score (Macro): {f1_macro:.4f}\")\n    print(\"=\"*60)\n    \n    # Detailed classification report\n    print(\"\\nCLASSIFICATION REPORT:\")\n    print(classification_report(y_true, y_pred, zero_division=0))\n    \n    # Confusion matrix\n    print(\"\\nCONFUSION MATRIX:\")\n    cm = confusion_matrix(y_true, y_pred)\n    unique_authors = sorted(results_df['true_author'].unique())\n    \n    # Create a simple confusion matrix display\n    print(f\"\\n{'':20s}\", end='')\n    for author in unique_authors:\n        print(f\"{author[:15]:>15s}\", end=' ')\n    print()\n    \n    for i, true_author in enumerate(unique_authors):\n        print(f\"{true_author[:20]:20s}\", end='')\n        for j in range(len(unique_authors)):\n            print(f\"{cm[i][j]:>15d}\", end=' ')\n        print()\n    \n    return {\n        'accuracy': accuracy,\n        'f1_weighted': f1_weighted,\n        'f1_macro': f1_macro\n    }\n\nif __name__ == \"__main__\":\n    print(\"Loading data...\")\n    \n    print(f\"Total samples: {len(df)}\")\n    print(f\"Unique authors: {len(df['author'].unique())}\")\n    print(f\"Authors: {df['author'].unique().tolist()}\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"Starting parallel classification...\")\n    print(f\"Using {len(API_KEYS)} API keys with rate limit of {RPM_LIMIT} RPM\")\n    print(\"=\"*60 + \"\\n\")\n    \n    start_time = time.time()\n    \n    results_df = parallel_classify(df, max_workers=8)\n    \n    elapsed_time = time.time() - start_time\n    \n    print(f\"\\n✓ Classification completed in {elapsed_time:.2f} seconds\")\n    print(f\"✓ Successfully processed {len(results_df)} out of {len(df)} samples\")\n    \n    results_df.to_csv('authorship_predictions.csv', index=False, encoding='utf-8-sig')\n    print(\"✓ Results saved to 'authorship_predictions.csv'\")\n    \n    metrics = evaluate_predictions(results_df)\n    \n    with open('evaluation_metrics.json', 'w', encoding='utf-8') as f:\n        json.dump(metrics, f, indent=2, ensure_ascii=False)\n    print(\"✓ Metrics saved to 'evaluation_metrics.json'\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open('/kaggle/working/evaluation_metrics.json', 'r') as f:\n    metrics = json.load(f)\n\naccuracy = metrics['accuracy']\n\nprint(f\"Accuracy: {accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:08:29.968371Z","iopub.execute_input":"2026-01-20T16:08:29.969180Z","iopub.status.idle":"2026-01-20T16:08:29.975007Z","shell.execute_reply.started":"2026-01-20T16:08:29.969150Z","shell.execute_reply":"2026-01-20T16:08:29.974172Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.12533333333333332\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"import json\n\nwith open('/kaggle/working/evaluation_metrics.json', 'r') as f:\n    metrics = json.load(f)\n\nprint(\"All metrics:\", metrics)\n\naccuracy = metrics.get('accuracy', None)\nprint(f\"Accuracy: {accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T16:08:30.676500Z","iopub.execute_input":"2026-01-20T16:08:30.676897Z","iopub.status.idle":"2026-01-20T16:08:30.684056Z","shell.execute_reply.started":"2026-01-20T16:08:30.676869Z","shell.execute_reply":"2026-01-20T16:08:30.683037Z"}},"outputs":[{"name":"stdout","text":"All metrics: {'accuracy': 0.12533333333333332, 'f1_weighted': 0.02791785150078989, 'f1_macro': 0.05568720379146919}\nAccuracy: 0.12533333333333332\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}